{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5e4dc8",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7917728",
   "metadata": {},
   "source": [
    "## Read packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math, random, time, zipfile, io\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "import copy\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torchvision import transforms, models\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.data_utils import *\n",
    "from src.cnn_models import *\n",
    "from src.training_utils import *\n",
    "from src.evaluation_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6116efca",
   "metadata": {},
   "source": [
    "## Read data-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cnn_personalized.ipynb\"  # Name of current file\n",
    "print(f\"Current absolute path: {os.getcwd()}\\n\")\n",
    "\n",
    "# We specify the path of the current directory and the data and output directories.\n",
    "ACTUAL_DIR = os.path.dirname(os.path.abspath(filename))\n",
    "BASE_DIR = os.path.dirname(ACTUAL_DIR)\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"output\")\n",
    "\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"IMG_DIR: {IMG_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "csv_file = os.path.join(DATA_DIR, \"train.csv\")\n",
    "df_train_complete = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1017d",
   "metadata": {},
   "source": [
    "## Init params\n",
    "Base parameters to use downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6789d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data related params\n",
    "prct_train = 0.85\n",
    "img_size = 256\n",
    "batch_size = 32\n",
    "weight_cap = 5  # for positive weight, to avoid too large weights\n",
    "\n",
    "### Base CNN ###\n",
    "# Base CNN architecture params\n",
    "base_ch = 16\n",
    "out_dim = 128\n",
    "base_dropout = 0.3\n",
    "\n",
    "# Base training params\n",
    "lr_base = 1e-4\n",
    "weight_decay_base = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79625f",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "Divide train and valid data.  \n",
    "Build the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weight of positive classes.\n",
    "# This will be useful whether the df is desbalanced\n",
    "# and for downstream training tasks\n",
    "\n",
    "# Use a weight cap to avoid too large weights\n",
    "\n",
    "if DEFAULT_COLS[\"class\"] in df_train_complete.columns:\n",
    "    # Calculate class counts\n",
    "    counts = (\n",
    "        df_train_complete[DEFAULT_COLS[\"class\"]]\n",
    "        .str.lower()\n",
    "        .map(CLASS_TO_LABEL)\n",
    "        .value_counts()\n",
    "    )\n",
    "    print(\"Class counts:\", counts.to_dict())\n",
    "\n",
    "    # Calculate pos_weight\n",
    "    pos = float(counts.get(1, 1.0))\n",
    "    neg = float(counts.get(0, 1.0))\n",
    "    positive_weight = torch.tensor(\n",
    "        [min(weight_cap, max(1.0, neg / max(1.0, pos)))], device=DEVICE\n",
    "    )\n",
    "    print(\"Calculated positive_weight:\", positive_weight.item())\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: 'class' column not found in DataFrame. Skipping pos_weight calculation.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ac676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and valid\n",
    "n = len(df_train_complete)\n",
    "n_train = math.floor(prct_train * n)\n",
    "n_valid = n - n_train\n",
    "\n",
    "# Shuffle and split\n",
    "df_shuffled = df_train_complete.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_valid = df_shuffled.iloc[n_train:].reset_index(drop=True)\n",
    "df_train = df_shuffled.iloc[:n_train].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total samples: {n}, Train samples: {n_train}, Valid samples: {n_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4167cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the Datasets and Dataloaders\n",
    "# In this case, we will use personalized normalization\n",
    "\n",
    "# Compute the mean and std per channel (R, G, B) across all training images\n",
    "mean_train_images, std_train_images = compute_mean_std_image_dir(\n",
    "    IMG_DIR, df_train[\"filename\"].tolist()\n",
    ")\n",
    "\n",
    "# Create the datasets with personalized normalization\n",
    "train_dataset = MaskDataset(\n",
    "    df=df_train,\n",
    "    images_dir=IMG_DIR,\n",
    "    img_size=img_size,\n",
    "    personalized_norm=True,\n",
    "    custom_mean=mean_train_images,\n",
    "    custom_std=std_train_images,\n",
    ")\n",
    "\n",
    "# Use the same normalization of training to avoid data leakage\n",
    "valid_dataset = MaskDataset(\n",
    "    df=df_valid,\n",
    "    images_dir=IMG_DIR,\n",
    "    img_size=img_size,\n",
    "    personalized_norm=True,\n",
    "    custom_mean=mean_train_images,\n",
    "    custom_std=std_train_images,\n",
    ")\n",
    "\n",
    "# Create the dataloaders\n",
    "num_workers = max(\n",
    "    4, int(os.cpu_count() / 2)\n",
    ")  # Use half of the available CPU cores, at least 4\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=(DEVICE == \"cuda\"),\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=2,\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=(DEVICE == \"cuda\"),\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9621f",
   "metadata": {},
   "source": [
    "# Base CNN \n",
    "Evaluate a basic backbone + basic decision head.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b78325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the base model\n",
    "base_backbone = BaseBackbone(base_ch=base_ch, out_dim=out_dim)\n",
    "\n",
    "# Wrap the backbone and add the decision head\n",
    "base_cnn_arch = TwoHeadNetVOC(\n",
    "    backbone=base_backbone, feat_dim=out_dim, dropout=base_dropout\n",
    ").to(DEVICE)\n",
    "\n",
    "# Define the optimizer and the accuracy metric\n",
    "optimizer = torch.optim.AdamW(\n",
    "    base_cnn_arch.parameters(), lr=lr_base, weight_decay=weight_decay_base\n",
    ")\n",
    "acc_metric = BinaryAccuracy().to(DEVICE)\n",
    "\n",
    "# Model summary\n",
    "summary(base_cnn_arch, (3, img_size, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87231107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration dictionary\n",
    "cfg = {\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"es_patience\": 3,\n",
    "    \"cls_loss_w\": 1.0,  # weight for classification loss\n",
    "    \"box_loss_w\": 1.0,  # weight for box regression loss\n",
    "    \"beta_smoothl1\": 1.0,\n",
    "    \"monitor\": \"val_score\",  # options: \"val_loss\", \"val_iou\", \"val_score\"\n",
    "    \"alpha_score\": 0.6,  # weight for IoU vs ACC\n",
    "    \"img_size\": img_size,  # image size\n",
    "    \"positive_weight\": positive_weight,\n",
    "    \"acc_metric\": acc_metric,\n",
    "    \"cnn_name\": \"cnn_base\",\n",
    "    \"output_dir\": OUTPUT_DIR,\n",
    "    \"logging_step\": 5,  # log every n steps\n",
    "    \"norm_mean\": mean_train_images,  # for personalized normalization\n",
    "    \"norm_std\": std_train_images,  # for personalized normalization\n",
    "}\n",
    "\n",
    "# Instantiate the trainer\n",
    "base_model = Trainer_base(\n",
    "    base_cnn_arch,\n",
    "    dl_train=dl_train,\n",
    "    dl_valid=dl_valid,\n",
    "    optimizer=optimizer,\n",
    "    cfg=SimpleNamespace(**cfg),\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Start the training\n",
    "history_base_model = base_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "plot_history(history_base_model, figsize=(13, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49519544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check of the predictions and show some examples\n",
    "sanity_check_batch(base_model)\n",
    "print()\n",
    "\n",
    "checkpoint_path = os.path.join(OUTPUT_DIR, \"cnn_base\", \"best_monitor_model.pt\")\n",
    "\n",
    "visualize_predictions(\n",
    "    model_class=base_cnn_arch,  # tu clase de red\n",
    "    checkpoint_path=checkpoint_path,  # ruta al .pt\n",
    "    dl_valid=dl_valid,  # tu dataloader de validación\n",
    "    n_images=3,  # número de imágenes a mostrar\n",
    "    n_cols=3,  # número de columnas en la grilla\n",
    "    threshold=0.5,  # umbral de clasificación (opcional)\n",
    "    device=DEVICE,  # o \"cpu\" si no tienes GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad34ef8",
   "metadata": {},
   "source": [
    "# Tunning the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c07e86",
   "metadata": {},
   "source": [
    "## Improve the backbone architecture\n",
    "Add more hidden layers and useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd469bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96bde92",
   "metadata": {},
   "source": [
    "## Improve the desicion head architecture\n",
    "Add more layers or useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fb55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e615dabb",
   "metadata": {},
   "source": [
    "## Hiperparameter tunning\n",
    "Test the results by tunning different values of hiperparameters:\n",
    "- d\n",
    "- d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b96cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170289fc",
   "metadata": {},
   "source": [
    "## Test Data augmentations\n",
    "Use different data augmentation techniques and identify those who are better to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dfeccc6",
   "metadata": {},
   "source": [
    "# Compare the results\n",
    "Show the metrics of the different models and compare the predictions on the images (validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf1a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "510655a8",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3114af",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c83bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ejemplo\n",
    "\n",
    "# backbone = BaseBackbone()\n",
    "\n",
    "# # Add an extra conv layer at the end of self.body\n",
    "# extra_layer = nn.Sequential(\n",
    "#     nn.Conv2d(4*32, 8*32, 3, 1, 1),\n",
    "#     nn.BatchNorm2d(8*32),\n",
    "#     nn.ReLU(inplace=True),\n",
    "# )\n",
    "\n",
    "# # Concatenate to the existing body\n",
    "# backbone.body = nn.Sequential(\n",
    "#     *(list(backbone.body.children()) + list(extra_layer.children()))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ejemplo\n",
    "\n",
    "# backbone = BaseBackbone()\n",
    "\n",
    "# # Replace projection with a deeper MLP\n",
    "# backbone.proj = nn.Sequential(\n",
    "#     backbone.proj,                      # original linear layer\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(backbone.proj.out_features, 256),  # new layer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42945f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
